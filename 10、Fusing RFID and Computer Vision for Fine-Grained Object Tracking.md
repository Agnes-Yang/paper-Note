## abstract
近年来，RFID和计算机视觉技术已经广泛应用于针对不同目标的室内场景，同时面临着各自的局限性。例如，基于RFID的EAS系统在快速识别标签物体方面是有用的，但是伴随的**虚警问题**是麻烦的并且难以处理，除了能够容易地获取目标标签的精确轨迹。另一方面，CV系统在精确跟踪多个移动物体方面表现相当出色，同时发现**难以筛选其中的特定目标**。为了克服上述局限性，我们提出TagVision，一种混合RFID和计算机视觉的系统，用于精确定位和跟踪标签物体。**提出一种融合算法，将CV子系统给出的位置信息和RFID子系统输出的相位数据有机地结合起来。此外，我们采用概率模型来消除热噪声和器件多样性造成的测量误差**。我们已经用COTS摄像头和RFID设备实施了TagVision，并在我们的实验室环境中进行了广泛的评估。实验结果表明，TagVision可以达到98％的斑点匹配精度和10.33mm的定位跟踪精度。
## introduction
无线射频识别技术作为本世纪最有前途的技术之一，在日常应用中得到了广泛的应用，如仓储库存，机场行李分拣，物流跟踪，图书馆图书订购等[ 1]，[2]。电子物品监视（EAS）系统最近使用的是RFID技术。根据去年的官方声明，全世界零售业商品总损失达到1234亿美元，占总收入的1.23％，不幸的是，77％的损失是由于偷窃造成的。为防止货物被盗，最初设计用于服装行业的EAS已经应用于许多百货公司，超市，图书馆等。

与传统的基于声磁的系统相比，基于RF的EAS采用UHF RFID设备因其**轻量，无线通信，自动识别和低成本**而受到好评。然而，由于其原理的局限性，现有的基于RFID的EAS系统正在遭受**虚警**的缺陷，从而大大降低了性能。这里，误报定义为用户实际没有进出警戒区时系统无意报告的误报。 B1 Bm图1：TagVision的说明虚假警报不仅给管理人员带来潜在的麻烦，而且会引起消费者和企业之间的冲突。仓库和物流管理领域也出现类似的问题。尽管基于RFID的技术在快速识别速度，集中管理，安全性等方面胜出，但是当与人工操作对抗时，误读问题（在接近检测区而不是通过它时误读货物）一起会造成信息失误，影响管理活动，甚至造成不必要的损失。所以总的来说，虚警（误读）是很多基于RFID应用的普遍问题，如何减少它是非常重要的。

**（解决虚警报问题的现有方法）**
解决这个问题的一个典型方法是设计一个**尽可能窄的辐射波瓣的专用天线**，这样不必要的读取的百分比可以最小化，但是这可能相对难以实现。或者，如果我们能够在**每个时刻获得标签的准确位置**，它可以帮助做出更好的决策。但是，标签定位本身是一个具有挑战性的任务，尤其是在backscatter系统中。

另一方面，近年来，计算机视觉（CV）技术的发展进入了一个显着的状态，可以在较低的开销下可靠地追踪视频片段中的物体或人物个体。 此外，摄像装置**价格低廉，在日常生活中广泛应用**。 我们可以从感兴趣的地区获得全面的监控图像，只需要一个小的预先放好的摄像头。 但是，也存在一些困扰CV系统的实际问题，例如在现场发现物品被盗，但监控摄像机可能有多人被摄像头捕捉，识别出真正的盗贼很困难。 如果将RFID标签预先附加到物品上，我们可以通过找出最有可能是标签的轨迹的轨迹来回溯目标。

基于以上所述，这项工作提出了TagVision，这是一种针对标签对象的细粒度识别和跟踪模式，它将RFID和CV融合在一起，使用一个COTS摄像头和RFID天线。图1显示了这个场景的一个玩具例子。存在多个移动对象（也称为运动点B1，B2，...），其中一个具有附加的RFID标签，而其他的不具有附加的RFID标签。 TagVision的基本思想如下。reader持续询问监视区域中的标签，在该区域中摄像机持续监视场景中的移动物体。TagVision首先安排**CV子系统给出所有当前运动点的精确轨迹追踪结果**。然后，对于检测到的RFID标签，TagVision会**尝试将其与最有可能是标签主机1的运动点相匹配**。具体来说，通过计算得出匹配分数并分配给每个运动点，运动点与RFID子系统下RFID阅读器报告的目标标签相位信息集成。最后，**标签将匹配具有最高分数的特定运动块**。同时也获取了目标标签在CV子系统的相应跟踪结果的精确轨迹**。

**贡献**：总之，本文做出以下贡献：
1. 首先，TagVision将计算机视觉和RFID技术进行了创新性的结合，实现对标签物体的高度准确跟踪，为解决RFID领域的实际问题提供了新的视角。
2. 第二，利用密集光流法和均值平移算法，实现运动斑点检测和跟踪机制。
3. 第三，融合算法被设计成将由CV子系统输出的位置信息无缝地链接到由RFID子系统收集的相位数据，从而成功处理由相位测量误差（由环境噪声和标签多样性引起）的负面影响。
4. 第四，我们纯粹用COTS摄像机和RFID产品来实施这个系统，并进行综合评估。经验证，TagVision可以将目标标签与其真实主机进行匹配，平均精确度高达98％，并以非常细的粒度跟踪标签。

本文的其余部分安排如下。 TagVision的主要设计在§II中概述。我们分别在§III和§Ⅳ中分别介绍TagVision的技术细节。 TagVision的实现在§V中描述并在§VI中进行评估。我们在§VII中回顾相关的工作，并在§VIII中总结本文。
## II overview
TagVision是一种针对标签移动物体的细粒度无源跟踪系统，它将CV与现有的RFID系统有机地结合在一起。为此，我们先来看看现有CV和RFID系统的优缺点。**CV在连续提供多个目标的准确位置评估方面表现良好，但未能区分彼此。 RFID阅读器可以高效地识别操作范围内的标签，而很难估计它们的准确位置**。所以我们可以把CV工具作为RFID系统的补充，因为它充分利用了这两个系统。在这项工作中，我们专注于定位和追踪**非高速移动的标签**。原因是当标签快速移动时，可能会造成严重的丢包，甚至导致无法读取，这已经超出了本文的范围。在这个场景中，有多个动作斑点，其中一个有附加的RFID标签。 TagVision部署了一个安装在天花板上的单眼相机，提供监控区域的鸟瞰图，和一个阅读器天线，以收集标签的相位信息。其基础设施还包括一个存储摄像机参数，天线坐标和其他系统设置的中央服务器。然后，TagVision通过以下步骤进行高级别追踪标签对象：
1. •相机将场景的图像帧记录一段时间，同时读取器询问附近的标签。之后，**图像数据和信号快照**被发送到服务器。 
2. •TagVision使用§III中的机制从图像数据中获取每帧中所有运动斑点的**即时实际坐标**。 
3. •TagVision从信号快照中获取并校准**相移**，并利用融合算法将标签与特定的运动块进行**匹配**（请参阅§IV）。

图2说明了TagVision的系统架构。整个系统由两个子系统组成：RFID子系统和CV子系统。接下来的几节将详细介绍上述步骤的技术细节。

## III CV SUBSYSTEM
在本节中，我们将介绍CV子系统如何工作，以及如何协助RFID子系统进行物体跟踪。 我们从CV领域的初步知识开始。
#### A. Detection and Tracking of Moving Objects
作为辅助部件，CV子系统设计用于检测和跟踪监控区域内的移动目标。 在相机捕获图像帧之后，斑点检测和跟踪模块经历图3的流程图中概述的步骤。它涉及两个连续的帧，其首先去往光流计算块以找到2D运动场。 光流是图像的亮度模式和数学术语中的明显运动（apparent motion，视运动，相对运动(???)），如果I（x，t）是在时间t的坐标x处的图像强度，则对于每个像素x，希望找到位移向量a满足：

I(x, t) = I(x + a, t + ∆t) (1)

我们采用卢卡斯 - 卡纳德光流法[3]来实现这一点。 然后，使用斑点检测模块来检测斑点实例（标记为B = {B1，B2，...，BM}）并且包括关于斑点大小和速度的若干约束。 为了跟踪连续帧上的单个斑点，应用均值漂移跟踪方法[4]。 **在对一定数量的帧进行采样后，我们可以构造每个运动对象Bi随时间变化的轨迹Li，它可以表示为位置和时间的两个元组，即Li = {（p_(i,1)，t1），（p_(i,2)，t2），...·}。 P_(i,j)表示在时间tj时图像中斑点Bi的位置**。
#### B. Coordinates Transformation（CV 矩阵变换得到。略）
到目前为止，我们获得的运动物体的轨迹被表示为摄像机图像平面中的像素值。 最终，我们需要的是物理世界坐标系中的轨迹。 所以这两个系统之间的相应转换是需要的。 为了更好的说明，我们从相机模型中的一些符号开始。 相机图像平面中的二维点由p = [u，v] T(矩阵的转置)表示，空间中的三维点由p = [X，Y，Z] T表示。2我们使用x〜来表示增广向量 加1作为最后一个元素：p〜= [u，v，1] T和P〜= [X，Y，Z，1] T。 照相机是用通常的针孔建模的，那么3D点P和它的图像投影p之间的关系由下式给出

cp˜ = A1A2P (2)

其中c是任意比例因子，A1和A2分别被称为摄像机固有矩阵和外部矩阵。 A2 = [R T]表示将世界坐标系与摄像机坐标系相关的旋转（R）和平移（T）。 A1是由以下给出
A1 =

α γ u0
0 β v0
0 0 1

其中（u0，v0）为主点坐标，α和β为图像u，v轴的比例因子，γ为描述两个图像轴偏斜度的参数。

实际上，台式相机通常使用镜头捕捉更多的光线，从而表现出明显的镜头失真，特别是径向失真。 令（x，y）为理想（不可观测的无失真）像素图像坐标，（x~，y~）为相应的实际（失真）观察图像坐标。 那么我们有[5]：：**略**
其中k1和k2是径向失真的系数。 径向畸变的中心与主点相同。

为了获得我们的跟踪对象的真实物理世界坐标，我们需要针对所有上述参数校准摄像机，即固有矩阵A1，外部矩阵A2和失真系数k1，k2。我们采用[6]中的技术，因为其简单性和鲁棒性。它通过使照相机观察在一些（至少两个）不同的方向上显示的平面图案（可以在激光打印机上打印并且附着到合理的平面表面，例如手册封面）来工作。无论是相机还是平面图案都可以用手移动，并且不需要知道其运动。图4显示了我们的相机校准的**实验设置**。模型平面是一个7×5格子图案，每个方形边长为41毫米，并有24个角落。要校准的摄像机是COTS AONI D881 HD720P摄像机。我们使用OpenCV实现我们的校准程序，并且在每个取得的不同方向下完成对24个图像的50个实验。表I列出了参数值的计算结果。指示相机旋转和平移的**外部矩阵**可以使用OpenCV中的solvePnP函数进一步计算，其中固有矩阵和失真系数作为**输入**。 在正确校准相机之后，我们可以将像素图像坐标系中的目标位置pi，j自动转换到现实世界位置Pi，j。 我们坐标变换的平均误差是1.56mm（见第六章B），这对于进一步的使用是足够的。
## IV. RFID SUBSYSTEM
在本节中，我们将详细介绍TagVision有关RFID子系统的技术细节。 如前所述，我们已经实现了使用基于CV的技术实时跟踪监控区域内的运动物体。 所以RFID子系统应该解决的问题是如何将RFID标签与其中一个轨迹相匹配.
#### A. Phase Model
RF相位是商业RFID读取器支持的常见参数。 如图1所示，假设d（t）是t时刻天线与标签之间的距离，则信号在后向散射通信过程中经过了来回2d(t)的总距离。 阅读器输出的总相位旋转可以表示为[7]：

θ(t) = (2π/λ× 2d(t) + θ_div)mod 2π

其中λ是波长。 变量θdiv是指与设备硬件特性有关的分集项。 相位是周期性2π弧度的周期函数，其在反向散射通信距离中每λ/ 2重复。 由于相位与距离直接相关，要更好地利用它，就要确定读写器与标签之间的几何关系。 但是在进行更深入的讨论之前，还有一些应该完成的预处理工作。

#### B. Preprocessing
1）**时钟同步**：考虑到CV子系统，我们得到了每个对象在K个不同时隙{t c 1，tc 2，...，t c K}上的完整轨迹。考虑到RFID子系统，我们在阅读器的总L个不同的时隙{t r 1，tr 2，...，t r L}上有相位序列。(tc，tr分别表示cv和rfid系统的时钟) 仔细的读者可能会注意到两个子系统时钟的不一致性，阻碍了我们对数据的准确处理。所以我们需要解决的第一个问题是两个子系统，即计算机和RFID阅读器之间的时间同步。我们选择互联网上的网络时间协议（NTP）作为解决方案。 NTP通常可以在局域网中提供优于1毫秒的精度。我们的想法是让计算机和阅读器连接到同一个NTP服务器“asia.pool.ntp.org”。为了获得足够的同步精度，我们应该在线配置读者足够的时间，以便它可以充分地与NTP服务器通信。

2）**时间戳变形**：虽然时间是同步的，但是读取器的询问率（〜60个采样/秒）和摄像机的帧速率（我们采用16fps）之间存在差距。 因此，两个子系统中的时间戳采样可能不一致。 为了克服这个问题，我们把CV子系统（以较低的采样率）作为基准，并且在任意时刻t c k，我们找到最接近t c k的时间戳t r l作为RFID子系统（频率高）中相应的时间戳。 公式如下所示：
trl = arg min |tri − tck |  t r i ∈{t r 1 ,tr 2 ,··· ,tr L} 
**arg min 就是使后面这个式子达到最小值时的变量的取值**

考虑到计算和时间成本，没有必要处理每个收集的样本，因此假设处理N个随机的原始数据快照。 在时钟同步和时间戳变形问题均解决的情况下，对于每个运动对象Bi（i = 1，...，M），每次快照tj（i = 1，...，N），我们可以得到它的位置 Pi，j和标签的对应相位值θj。 这里注意，为了方便，我们在两个子系统中使用相同的时间符号tj。
#### C. Fusion Algorithm
正如我们前面提到的，RFID子系统的关键在于阅读器和目标标签之间的几何关系，这又可以从CV子系统输出的跟踪结果推断出来。 融合算法被设计为巧妙地将来自两个子系统的两种类型的数据关联起来。 天线表示为A，坐标为（xA，yA，zA）。 令ϑi,j为时间tj处第i个物体的理论相位值。 忽略分集项（θ_div），ϑi,j可以计算如下：
ϑi,j =4π/λx|Pi,jA| mod 2π
其中| ·| 测量位置P和A之间的欧几里得距离：（略）

我们知道，阅读器输出的标签相位旋转与多样性因子(或分集因子，diversity factor)θ_div相关联。 所以测量的相位与理论相位之间存在偏差。 进行实证研究以更好地理解。 我们把一个标签贴在玩具火车上，当读写器位于（120cm，0）时，沿着x = 10cm（-70cm≤y≤70cm）的线性轨道以7cm / s的均匀速度移动。 图5（a）显示了收集的相移和地面实况。 基本事实是使用公式 通过比较，我们发现它们之间有大约3.2弧度的偏差，这是由θdiv造成的。 由于在相同的宏观环境（例如，相同的温度，湿度等）下偏差保持相对不变，所以假定θdiv是所获得的相序中的常数项是合理的。 那么我们可以用第一个相位值作为参考来消除错位的影响
θ(ti)−θ(t1) = (ϑ(ti) + θdiv)−(ϑ(t1) + θdiv) = ϑ(ti)−ϑ(t1)
符号θ表示相应的理论相位值。 通过这样去除θdiv项。 图5（b）显示了**（相位）校准**器件分集后的结果。 两个序列都相互同步。

我们提出了**融合算法**，该算法通过将获得的相位序列与每个运动斑点（称为斑点匹配）进行匹配，并将匹配得分分配给每个轨迹。 整个过程总结在算法1中。匹配得分表示相应对象可能是标签主机的可能性，匹配得分越高表明标签更可能在该轨迹上。 那么问题是如何定义匹配分数。 已知标签的相位测量结果包含随机误差，其遵循具有0.1弧度的标准偏差的典型高斯分布，即θ−ϑ ∼ N (0, 0.1)。 因此，我们应该把测量的相位视为一个高斯随机变量而不是一个常数值。 基于此，采用概率模型来定义第i个运动块的匹配得分si，其由下式给出：
略

f（x;μ，σ）是高斯分布N（μ，σ）的概率密度函数（PDF），θi，j可以用公式 4和Eqn。5。

术语J表示虚数单位，我们用复数eJθ表示单位幅度的无线信号。注意θref = (θj − θ1) − (ϑi,j − ϑi,1) = (θj − ϑi,j ) − (θ1 − ϑi,1)。假设标签在第i个运动块上，那么(θj−ϑi,j ) ∼ N (0, 0.1) 和 (θ1−ϑi,1) ∼ N (0, 0.1), 所以 θref ∼ N (0, 0.1× √ 2)。分配的权重wi，j表示测量的相位从A发射并且在时间tj在第i个斑点后向散射的概率。通过这样做，对于具有较高可能性的对象而言，匹配分数被增强，成为基本事实并削弱其他斑点。如果标签实际上在Blob Bi上，则理论相位应该等于测量的相位。 eJθref的矢量将接近实轴，并且由于θref接近0，因此wi，j将达到其最大值。来自不同信号快照的所有观察值彼此相加。否则，如果Bi不是基本事实，则理论阶段和测量阶段之间会有偏差。然后wi，j将会得到一个较小的值，不同的信号观察相互抵消，导致所有快照的最终叠加到低得多的水平。

对于在CV子系统中检测到的每个运动对象Bi，我们可以使用上述融合算法计算相应的匹配分数si。 此外，为了避免偶然性，增强我们的方法的鲁棒性，我们重复运行融合算法**几次迭代，每次随机采样数据并平均化结果**。 最终，标签可以匹配到具有最高匹配分数的特定移动对象：
m = arg max si i∈{1,2,··· ,M}

然后Bm作为目标输出。 标签的轨迹Lm也同时从CV子系统中检索。 这是我们方法完成的工作流程。 在更复杂的情况下，多个对象可能同时被盗。 直观地看，我们可以对每个识别的标签重复上述匹配过程，并使用更多的天线来减少多路径的影响，这构成了我们未来工作的一部分。
#### D.Simulation Results
为了证明我们方法的可行性，我们模拟了一个典型的室内场景，如图6所示：沿着x轴以6mm的间隔生成101条线性轨迹，即X1 = -300，X2 = -294，· ··，X101 = 300。基本事实是X51 = 0标记为红色，读者位于（1018mm，0）。这里为了表达，我们考虑2D平面上的轨迹。对于每次迭代，我们在每个轨迹上随机选择[-300，300]的y轴范围内的30个采样点，并使用我们的融合算法计算相应的匹配分数。在我们的模拟中采用的相位值是通过将白高斯噪声加到理论值而产生的。图6（b）和图6（c）分别是一次迭代和100次迭代的平均结果。使用最大值作为参考对匹配分数进行归一化。我们可以清楚地看到，无论在哪种情况下，与其他轨迹相比，基本事实都具有绝对高的价值。此外，图6（c）中的结果比图6（b）中的结果更均匀。这是因为一次抽样可能会给结果带来不确定性，但是通过大量抽样并取平均值，可以减少一些偏差值，使结果更具说服力。可以看出，虽然标签的实际轨迹最大匹配分数为1，但其他轨迹的幅度要小得多，几乎都在0.075以下。这证实了我们方法的有效性。

## V. IMPLEMENTATION
我们使用COTS相机和UHF RFID设备构建TagVision的原型。

硬件：在CV子系统中，我们使用一个AONI D881 HD720P摄像机[8]，它可以支持高达60fps的帧率。相机便宜，只需要约100元人民币。在RFID子系统中，采用了兼容EPC Gen2标准的ImpinJ Speedway Revolution R420读写器[9]，默认在920.5〜924.5 MHz的频段内工作。我们只使用一种由Yeon技术制造的圆极化天线[10]，其尺寸为225mm×225mm×40mm。阅读器通过无线网络连接到我们的主机端。采用了Alien公司[11]提供的两种标签，尺寸为44×46mm2的“2×2”和尺寸为44.5×10.4mm2的“Squig”。两者都是低成本的（平均每个标签只有大约5美分）。

软件：采用C / C ++语言，采用OpenCV计算机视觉库，在CV子系统中实现包括摄像机标定和目标跟踪在内的算法。对于RFID子系统，我们采用LLRP（低层次阅读器协议）[7]与读者进行交流。 ImpinJ阅读器扩展了这个协议来支持阶段报告。我们调整阅读器的配置，以便在检测到标签时立即报告其读数。客户端代码使用Java语言实现。我们还注意到并解决了前面在§IV-B中提到的两个子系统时钟之间的时间同步问题。我们使用戴尔个人电脑来运行我们所有的程序，以及在LLRP下连接到阅读器。该机配备3.1GHz的英特尔酷睿i5-4440 CPU和8GB内存

## VI. EVALUATION
